{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place de la caméra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de la caméra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la classe Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import threading\n",
    "import atexit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera(traitlets.HasTraits):\n",
    "    type_camera = traitlets.Unicode(\"CSI\")\n",
    "    capture_device = traitlets.Integer(default_value=0)\n",
    "    capture_width = traitlets.Integer(default_value=1280)\n",
    "    capture_height = traitlets.Integer(default_value=720)\n",
    "    display_width = traitlets.Integer(default_value=640)\n",
    "    display_height = traitlets.Integer(default_value=480)\n",
    "    fps = traitlets.Integer(default_value=30)\n",
    "    flip = traitlets.Integer(default_value=0)\n",
    "    image = traitlets.Any()\n",
    "    video_on = traitlets.Bool(default_value=False)\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "        self._running = False\n",
    "        self.image = np.empty((self.display_height, self.display_width, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "    \n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            image_resized = cv2.resize(image,(int(self.display_width),int(self.display_height)))\n",
    "        return image_resized\n",
    "    \n",
    "    # ON/OFF de la capture vidéo\n",
    "    def capture_video(self,run=False):\n",
    "        if run is True:\n",
    "            self.video_on = True\n",
    "        else:\n",
    "            self.video_on = False\n",
    "    \n",
    "    # Lecture d'un flux vidéo\n",
    "    def _capture_video(self):\n",
    "        while True:\n",
    "            if not self._running:\n",
    "                break\n",
    "            self.image = self.capture_image()\n",
    "\n",
    "            \n",
    "    # Détachement de la caméra\n",
    "    def release(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))\n",
    "    \n",
    "    # Surveillance de la variable \"video_on\"\n",
    "    @traitlets.observe('video_on')\n",
    "    def _on_running(self, change):\n",
    "        if change['new'] and not change['old']:\n",
    "            # not running -> running\n",
    "            self._running = True\n",
    "            self.thread = threading.Thread(target=self._capture_video)\n",
    "            self.thread.start()\n",
    "        elif change['old'] and not change['new']:\n",
    "            # running -> not running\n",
    "            self._running = False\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciation de la classe Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitCamera():\n",
    "    camera = Camera(type_camera=\"USB\",capture_device=0,\n",
    "                capture_width=640,capture_height=480,\n",
    "                display_width=224,display_height=224,\n",
    "                fps=30,flip=0)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des données d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par créer une interface à l'aide des widgets permettant de récupérer les données et de les sauvegarder dans un dictionnaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TACHE = \"visage\"\n",
    "CATEGORIES = ['nez']\n",
    "\n",
    "datasets = {}\n",
    "for name in CATEGORIES:\n",
    "    datasets[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "camera = InitCamera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import urllib3\n",
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "\n",
    "# Initialise la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "camera = InitCamera()\n",
    "\n",
    "# Création du widget \"cliquable\" de la vidéo\n",
    "camera_widget = ClickableImageWidget(width=camera.display_width,height=camera.display_height)\n",
    "camera_widget.add_class('classe_camera')\n",
    "traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Création du widget de visualisation de la capture de l'image\n",
    "url = \"https://github.com/AlexandreBourrieau/JetsonNano/blob/main/images/ready_img.jpg?raw=true\"\n",
    "http = urllib3.PoolManager()\n",
    "image = http.request(\"GET\",url)\n",
    "image = np.asarray(bytearray(image.data), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "image = cv2.resize(image,(int(camera.display_width),int(camera.display_height)))\n",
    "\n",
    "capture_widget = ipywidgets.Image(value=image.tobytes(),width=camera.display_width,height=camera.display_height)\n",
    "\n",
    "# Création des widgets de l'interface\n",
    "category_widget = ipywidgets.Dropdown(options=CATEGORIES, description='Catégorie')\n",
    "count_widget = ipywidgets.IntText(description='Nombre')\n",
    "\n",
    "# Mise à jour du nombre de données dans les catégories\n",
    "def update_counts(change):\n",
    "    count_widget.value = len(datasets[change['new']])\n",
    "count_widget.value = len(datasets[category_widget.value])\n",
    "category_widget.observe(update_counts, names='value')\n",
    "\n",
    "# Prise d'une image\n",
    "def save(_,content,msg):\n",
    "    if content['event'] == 'click':\n",
    "        # Récupère les coordonnées (X,Y) du clic\n",
    "        data = content['eventData']\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        \n",
    "        # Sauvegarde de l'image et des coordonnées\n",
    "        datasets[category_widget.value].append([camera.image,x,y])\n",
    "\n",
    "        # Affiche la capture de l'image avec la zone du clic\n",
    "        capture_image = camera.image.copy()\n",
    "        capture_image = cv2.circle(capture_image, (x,y), 8, (0,255,0), 3)\n",
    "        capture_widget.value = bgr8_to_jpeg(capture_image)\n",
    "        \n",
    "        # Mise à jour du compteur d'image\n",
    "        count_widget.value = len(datasets[category_widget.value])\n",
    "camera_widget.on_msg(save)\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget,capture_widget]), category_widget, count_widget])\n",
    "\n",
    "# Lancement de la vidéo\n",
    "camera.capture_video(run=True)\n",
    "camera_link = traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Affiche l'interface\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont sauvegardées en respectant la structure requise par la fonction tf.keras.preprocessing.image_dataset_from_directory : https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire_courant = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des répertoires de sauvegarde\n",
    "try:\n",
    "    shutil.rmtree(repertoire_courant+\"/projet_regression/\"+TACHE)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "for i in range(len(CATEGORIES)):\n",
    "    try:\n",
    "        shutil.rmtree(repertoire_courant+\"/projet_regression/\"+TACHE+\"/\"+CATEGORIES[i])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    os.makedirs(repertoire_courant+\"/projet_regression/\"+TACHE+\"/\"+CATEGORIES[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement des images\n",
    "for i in range (len(CATEGORIES)):\n",
    "    n = 0\n",
    "    for image,x,y in datasets[CATEGORIES[i]]:\n",
    "        n = n+1\n",
    "        cv2.imwrite(repertoire_courant+\"/projet_regression/\"+TACHE+\"/\"+CATEGORIES[i]+\"/\"+CATEGORIES[i]+\"_image_%d_%d_%d.jpg\" %(n,x,y),image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chargement des images dans le dataset de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des images sauvegardées dans le répertoire de travail, on peut maintenant créer notre dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "dataset_entrainement = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    repertoire_courant+\"/projet_regression/\"+TACHE,\n",
    "    validation_split=0.0,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset_entrainement.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons quelques labels codé de manière \"categorical\" et leur valeur équivalente \"binaire\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(1):\n",
    "    print(image.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérons maintenant les répertoires associés aux images du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoires_images = dataset_entrainement.file_paths\n",
    "repertoires_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_entrainement.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modification du dataset d'entrainement en type regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va transformer le dataset de la manière suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/AlexandreBourrieau/JetsonNano/blob/main/images/datset_regression_heatmap2.png?raw=true\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par vérifier la correspondance des labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nez :         [1 0 0] => label binaire : 0\n",
    "\n",
    "for image,label in dataset_entrainement.take(16):\n",
    "    print(\"Label categorical : %s\" %label[0])\n",
    "    print(\"Label binaire correspondant : %s\" %np.argmax(label[0], axis=None, out=None))\n",
    "    print(\"Classe correspondante : %s\" %class_names[np.argmax(label[0], axis=None, out=None)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Création des heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par définir la fonction permettant de créer le heatmap :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K\\left( {x,y} \\right) = \\exp \\left( { - \\frac{{{{\\left( {x - {x_0}} \\right)}^2}}}{{2\\sigma _x^2}} - \\frac{{{{\\left( {y - {y_0}} \\right)}^2}}}{{2\\sigma _y^2}}} \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.4\n",
    "sigma_x = alpha*camera.display_width/6.0\n",
    "sigma_y = alpha*camera.display_height/6.0\n",
    "\n",
    "def CreateHeatmap(x, y, x0, y0):\n",
    "    return np.exp(-((x - x0)**2. / (2. * sigma_x**2.) + (y - y0)**2. / (2. * sigma_y**2.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de heatmap basé sur une image en entrée de (224,224) puis réduit en sortie d'un coefficient de (1/4) avec l'opération de max_pooling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug.augmentables.heatmaps import HeatmapsOnImage\n",
    "\n",
    "x0 = 50\n",
    "y0 = 100\n",
    "x,y = np.meshgrid(np.linspace(0,camera.display_width-1,camera.display_width), np.linspace(0,camera.display_height-1,camera.display_height))\n",
    "z = CreateHeatmap(x,y,x0,y0).astype(np.float32)\n",
    "\n",
    "z = HeatmapsOnImage(z, (camera.display_width,camera.display_height), min_value=0.0, max_value=1.0)\n",
    "z = z.max_pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(z.get_arr()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.get_arr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_min(tf.convert_to_tensor(z.get_arr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z.get_arr()[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sh_0, sh_1 = z.get_arr()[:,:,0].shape\n",
    "x, y = np.linspace(0, sh_0-1, sh_0), np.linspace(0, sh_1-1, sh_1)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=z.get_arr()[:,:,0], x=x, y=y)])\n",
    "fig.update_layout(autosize=False,\n",
    "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Création des dataset pour la régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit maintenant une fonction pour créer notre dataset pour la régression. Il faut prendre en compte le fait que le heatmap doit être réduit à la dimension de sortie des images créées par le modèle.  \n",
    "On choisit un coefficient de réduction de (1/4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug.augmentables.heatmaps import HeatmapsOnImage\n",
    "\n",
    "# Fonction de création du dataset d'entrainement\n",
    "# à partir de la liste des fichiers contenus dans\n",
    "# le dataset de classification\n",
    "\n",
    "# /home/alexandre/projet_regression/visage/oeil_droit/oeil_droit_image_6_217_181.jpg\n",
    "\n",
    "def CreationDatasetRegression(liste_fichiers,noms_classes):\n",
    "    heatmap_ = [[] for i in range(len(noms_classes))]\n",
    "    images_= []\n",
    "\n",
    "    width = camera.display_width\n",
    "    height = camera.display_height\n",
    "\n",
    "    # Création du heatmap nul\n",
    "    heatmap_zero = np.zeros((height,width)).astype(np.float32)\n",
    "    heatmap_zero = HeatmapsOnImage(heatmap_zero, shape=(height,width), min_value=0.0, max_value=1.0)\n",
    "    heatmap_zero = heatmap_zero.avg_pool(4)\n",
    "\n",
    "    # Création de la grille pour le heatmap\n",
    "    x,y = np.meshgrid(np.linspace(0,width-1,width), np.linspace(0,height-1,height))\n",
    "    \n",
    "    # Définition des constantes pour le heatmap\n",
    "    alpha = 0.4\n",
    "    sigma_x = alpha*camera.display_width/6.0\n",
    "    sigma_y = alpha*camera.display_height/6.0\n",
    "    \n",
    "    # Conversion des classe du heatmap zero en tenseur 1D\n",
    "    # (56,56,nbr_classes)\n",
    "    heatmap_zero = tf.convert_to_tensor(heatmap_zero.get_arr())\n",
    "\n",
    "    for fichier in liste_fichiers:\n",
    "        # Chargement de l'image\n",
    "        image = tf.keras.preprocessing.image.load_img(fichier)\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        # Extraction des coordonnées (x0,Y0)\n",
    "        # correspondantes aux dimensions de l'image chargée (height,width)\n",
    "        element = tf.strings.split(fichier,sep=\"_image_\")\n",
    "        element = tf.strings.split(element[1],sep=\"_\")\n",
    "        x0 = tf.strings.to_number(element[1],out_type=tf.dtypes.float32)\n",
    "        y0 = tf.strings.split(element[2],sep=\".\")\n",
    "        y0 = tf.strings.to_number(y0[0],out_type=tf.dtypes.float32)\n",
    "        \n",
    "        # Extraction de la classe\n",
    "        classe = tf.strings.split(fichier,sep=\"/\")[-2]\n",
    "        \n",
    "        # Extraction du label\n",
    "        label = tf.cast(tf.strings.regex_full_match(noms_classes, classe),dtype=\"int32\")\n",
    "        \n",
    "        # Extraction de la valeur binaire du label\n",
    "        maxi = tf.math.argmax(label,output_type=tf.dtypes.int32)\n",
    "        \n",
    "        # Création du heatmap de l'image\n",
    "        heatmap = CreateHeatmap(x,y,x0,y0).astype(np.float32)\n",
    "        heatmap = HeatmapsOnImage(heatmap, (height,width,1), min_value=0.0, max_value=1.0)\n",
    "        heatmap = heatmap.max_pool(4)\n",
    "        \n",
    "        # Sauvegarde du heatmap et de l'image dans les listes\n",
    "        for i in range(len(noms_classes)):\n",
    "            if i == maxi:\n",
    "                heatmap = tf.convert_to_tensor(heatmap.get_arr())\n",
    "                heatmap_[i].append(heatmap)\n",
    "            else:\n",
    "                heatmap_[i].append(heatmap_zero)\n",
    "        images_.append(image)\n",
    "   \n",
    "    # Création du dataset\n",
    "    images_ = tf.convert_to_tensor(images_)                                # (nbr_images,H,W,3)\n",
    "    heatmap_ = tf.convert_to_tensor(heatmap_)                              # (nbr_images,H/4,W/4,1)\n",
    "    heatmap_ = tf.transpose(heatmap_,perm=[1,2,3,0,4])                     # (nbr_image,H/4,W/4)\n",
    "    heatmap_ = tf.squeeze(heatmap_,-1)                                     # (nbr_image,H/4,W/4)\n",
    "\n",
    "    datasetHeatmap = tf.data.Dataset.from_tensors(heatmap_)                # (nbr_images,3,H/4,W/4)\n",
    "    datasetImg = tf.data.Dataset.from_tensors(images_)                     # (nbr_images,H,W,3) \n",
    "    dataset = tf.data.Dataset.zip((datasetImg,datasetHeatmap))\n",
    "\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé notre dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_regression = CreationDatasetRegression(repertoires_images,dataset_entrainement.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,heatmap in dataset_regression.take(1):\n",
    "    print(image.shape)\n",
    "    print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On redimensionne le dataset au bon batch_size :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_regression = dataset_regression.unbatch()\n",
    "dataset_regression = dataset_regression.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,heatmap in dataset_regression.take(1):\n",
    "    print(image.shape)\n",
    "    print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(dataset_regression.unbatch())\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):\n",
    "    image, heatmap = iterator.get_next()\n",
    "    ax = plt.subplot(4, 2, 2*i+1)\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    plt.title(\"image\")\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.subplot(4, 2, 2*i+2)\n",
    "    plt.imshow(heatmap[:,:,0])\n",
    "    plt.title(\"heatmap\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de pré-traitement avec le modèle Restnet18 utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de regression basé sur Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La structure de notre modèle est la suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/AlexandreBourrieau/JetsonNano/blob/main/images/Resnet18.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CreateRegressionModel import GetRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle de régression\n",
    "base_model = GetRegressionModel(image_width=camera.display_width,image_height=camera.display_height,n_labels=len(class_names))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désactivation des couches pour l'entrainement\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des couches du modèle\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[78:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la fonction d'erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE : Mean Squared Error (Erreur Quadradique Moyenne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur quadratique moyenne correspond au calcul de l'écart type :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$mse = \\frac{1}{N}\\sum\\limits_{i \\in H,W} {{{\\left( {{y_i} - {{\\hat y}_i}} \\right)}^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N : Nombre total de pixel du heatmap  \n",
    "H : Hauteur ; W : Largeur ;  \n",
    "${y_i}$ : Vraie valeur du pixel du heatmap  \n",
    "${{\\hat y}_i}$ : Prédiction de la valeur du pixel du heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur_mse(y_true,y_predict):\n",
    "    # y_true : (batch_size,56,56,1)\n",
    "    # y_pred : (batch_size,56,56,1)\n",
    "    return tf.keras.losses.mse(y_true,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAE : Mean Absolute Error (Erreur Absolue Moyenne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur absolue moyenne est la moyenne des valeurs absolues des erreurs :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$mae = \\frac{1}{N}\\sum\\limits_{i \\in H,W} {\\left| {{y_i} - {{\\hat y}_i}} \\right|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N : Nombre total de pixel du heatmap  \n",
    "H : Hauteur ; W : Largeur ;  \n",
    "${y_i}$ : Vraie valeur du pixel du heatmap  \n",
    "${{\\hat y}_i}$ : Prédiction de la valeur du pixel du heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur_mae(y_true,y_predict):\n",
    "    return tf.keras.losses.mae(y_true,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Focal loss : Erreur focale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette erreur est spécifiquement utilisé dans la détection d'image :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$focal = \\sum\\limits_{i \\in H,W} {\\left\\{ \\begin{array}{l}\n",
    "{\\left( {1 - {{\\hat y}_i}} \\right)^\\alpha }\\log \\left( {{{\\hat y}_i}} \\right){\\rm{\\quad \\quad \\quad \\quad \\ si \\ }}{y_i}{\\rm{ = 1 }}\\\\\n",
    "{\\left( {1 - {y_i}} \\right)^\\beta }{{\\hat y}_i}^\\alpha \\log \\left( {1 - {{\\hat y}_i}} \\right){\\rm{\\qquad sinon}}\n",
    "\\end{array} \\right.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha$ et $\\beta$ sont des hyperparamètres. Souvent on prend : $\\alpha$ = 4.0 et $\\beta$ = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus de détails dans ce document de recherche :https://arxiv.org/pdf/1708.02002.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur_focal_loss(y_true,y_predict):\n",
    "    pos_mask = tf.cast(tf.equal(y_true, 1.0), dtype=tf.float32)\n",
    "    neg_mask = tf.cast(tf.less(y_true, 1.0), dtype=tf.float32)\n",
    "    neg_weights = tf.pow(1.0 - y_true, 4)\n",
    "\n",
    "    pos_loss = -tf.math.log(tf.clip_by_value(y_predict, 1e-5, 1.0 - 1e-5)) * tf.math.pow(1.0 - y_predict, 2.0) * pos_mask\n",
    "    neg_loss = (\n",
    "        -tf.math.log(tf.clip_by_value(1.0 - y_predict, 1e-5, 1.0 - 1e-5))\n",
    "        * tf.math.pow(y_predict, 2.0)\n",
    "        * neg_weights\n",
    "        * neg_mask\n",
    "    )\n",
    "\n",
    "    num_pos = tf.reduce_sum(pos_mask)\n",
    "    pos_loss = tf.reduce_sum(pos_loss)\n",
    "    neg_loss = tf.reduce_sum(neg_loss)\n",
    "\n",
    "    loss = tf.cond(tf.greater(num_pos, 0), lambda: (pos_loss + neg_loss) / num_pos, lambda: neg_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de périodes d'entrainement\n",
    "periodes = 30\n",
    "\n",
    "# Entrainement du modèle\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001*batch_size)\n",
    "base_model.compile(optimizer=opt, loss=erreur_focal_loss)\n",
    "base_model.fit(dataset_regression,verbose=1,epochs=periodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface de capture d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import urllib3\n",
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "# Initialise la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "camera = InitCamera()\n",
    "\n",
    "# Création du widget \"cliquable\" de la vidéo\n",
    "camera_widget = ClickableImageWidget(width=camera.display_width,height=camera.display_height)\n",
    "camera_widget.add_class('classe_camera')\n",
    "traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Lancement de la vidéo\n",
    "camera.capture_video(run=True)\n",
    "camera_link = traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Prise d'une image\n",
    "def save(_,content,msg):\n",
    "    global image_test\n",
    "    if content['event'] == 'click':\n",
    "        image_test = camera.image\n",
    "camera_widget.on_msg(save)\n",
    "\n",
    "display(camera_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiciton du heatmap avec le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_heat = base_model(tf.expand_dims(image_test,0))\n",
    "predict_heat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "plt.imshow(image_test)\n",
    "plt.title(\"image\")\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "plt.imshow(predict_heat[0,:,:,0])\n",
    "plt.title(\"heatmap\")\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "heatmapOnImage = HeatmapsOnImage(np.asarray(predict_heat[0,:,:,0]), shape=(56,56), min_value=0.0, max_value=1.0)\n",
    "plt.imshow(np.asarray(heatmapOnImage.draw_on_image(image_test))[0,:,:,:])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe de récupération des coordonnées de la cible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par traiter le heatmap afin d'accentuer les zones à fortes valeurs. Pour cela :\n",
    "- On applique une opération de MaxPooling sur le heatmap, ce qui va élargir un petit peu les zones à fortes valeurs\n",
    "- On vient ensuite masquer le résultat du MaxPooling avec le heatmap original afin de ne garder que les valeurs en commun\n",
    "- On applique le résultat obtenu pour filtrer le MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmax = tf.keras.layers.MaxPooling2D(3, 1, padding=\"same\")(predict_heat)\n",
    "keep = tf.cast(tf.equal(predict_heat, hmax), tf.float32)\n",
    "prod = hmax*keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 6, 1)\n",
    "plt.imshow(image_test)\n",
    "plt.title(\"image\")\n",
    "\n",
    "ax = plt.subplot(1, 6, 2)\n",
    "plt.imshow(predict_heat[0,:,:,0])\n",
    "plt.title(\"heatmap\")\n",
    "\n",
    "ax = plt.subplot(1, 6, 3)\n",
    "plt.title(\"MaxPooling\")\n",
    "plt.imshow(hmax[0,:,:,0])\n",
    "\n",
    "ax = plt.subplot(1, 6, 4)\n",
    "plt.title(\"masquage\")\n",
    "plt.imshow(keep[0,:,:,0])\n",
    "\n",
    "ax = plt.subplot(1, 6, 5)\n",
    "plt.title(\"produit\")\n",
    "plt.imshow(prod[0,:,:,0])\n",
    "\n",
    "ax = plt.subplot(1, 6, 6)\n",
    "heatmapOnImage = HeatmapsOnImage(np.asarray(prod[0,:,:,0]), shape=(56,56), min_value=0.0, max_value=1.0)\n",
    "plt.imshow(np.asarray(heatmapOnImage.draw_on_image(image_test))[0,:,:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sh_0, sh_1 = predict_heat[0,:,:,0].shape\n",
    "x, y = np.linspace(0, sh_0-1, sh_0), np.linspace(0, sh_1-1, sh_1)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=predict_heat[0,:,:,0], x=x, y=y)])\n",
    "fig.update_layout(autosize=False,\n",
    "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sh_0, sh_1 = predict_heat[0,:,:,0].shape\n",
    "x, y = np.linspace(0, sh_0-1,sh_0), np.linspace(0, sh_1-1,sh_1)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=hmax[0,:,:,0], x=x, y=y)])\n",
    "fig.update_layout(autosize=False,\n",
    "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sh_0, sh_1 = predict_heat[0,:,:,0].shape\n",
    "x, y = np.linspace(0, sh_0-1, sh_0), np.linspace(0, sh_1-1, sh_1)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=keep[0,:,:,0], x=x, y=y)])\n",
    "fig.update_layout(autosize=False,\n",
    "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sh_0, sh_1 = predict_heat[0,:,:,0].shape\n",
    "x, y = np.linspace(0, sh_0-1, sh_0), np.linspace(0, sh_1-1, sh_1)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=prod[0,:,:,0], x=x, y=y)])\n",
    "fig.update_layout(autosize=False,\n",
    "                  scene_camera_eye=dict(x=1.87, y=0.88, z=-0.64),\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vient ensuite récupérer les index des pixels les plus forts avec la méthode https://www.tensorflow.org/api_docs/python/tf/math/top_k à partir du résultat applati :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_applati = tf.reshape(prod, (1, -1))\n",
    "prod_applati.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, index = tf.nn.top_k(prod_applati, k=1)\n",
    "print(scores)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, prod_applati[0,:].shape[0]-1, prod_applati[0,:].shape[0])\n",
    "\n",
    "plt.plot(x,np.asarray(prod_applati[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite il faut convertir les coordonnées dans l'espace (X,Y) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_heat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.cast(index % predict_heat[0,:,:,0].shape[1], tf.float32)\n",
    "ys = tf.cast(index // predict_heat[0,:,:,0].shape[0], tf.float32)\n",
    "\n",
    "print(xs)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image_test)\n",
    "plt.plot(xs*4,ys*4,'bo')\n",
    "plt.title(\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la fonction extraction des coordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCoordFromHeatmap(heatmap,sampling=4):\n",
    "    hmax = tf.keras.layers.MaxPooling2D(3, 1, padding=\"same\")(heatmap)\n",
    "    keep = tf.cast(tf.equal(heatmap, hmax), tf.float32)\n",
    "    prod = hmax*keep\n",
    "\n",
    "    # Applatissement\n",
    "    prod_applati = tf.reshape(prod, (1, -1))\n",
    "    \n",
    "    # Récupère les index du maximum\n",
    "    scores, index = tf.nn.top_k(prod_applati, k=1)\n",
    "    \n",
    "    # Calcul des coordonnées\n",
    "    xs = tf.cast(index % heatmap[0,:,:,0].shape[1], tf.float32)\n",
    "    ys = tf.cast(index // heatmap[0,:,:,0].shape[0], tf.float32)\n",
    "    return xs*sampling,ys*sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'interface d'acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialise la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "camera = InitCamera()\n",
    "\n",
    "# Création du widget de la vidéo\n",
    "camera_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Lancement de la vidéo\n",
    "camera.capture_video(run=True)\n",
    "camera_link = traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Création des widgets\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "category_widget = ipywidgets.Dropdown(options=CATEGORIES, description='Catégorie')\n",
    "preview_widget = ipywidgets.Image(format=\"jpeg\",width=camera.display_width, height=camera.display_height, value=bgr8_to_jpeg(camera.image))\n",
    "\n",
    "# Fonction de traitement des actions du widget \"state_widget\"\n",
    "def live(state_widget, model, camera):\n",
    "    while state_widget.value == 'live':\n",
    "        # Capture de l'image\n",
    "        image = camera.image\n",
    "       \n",
    "        # Récupération de la catégorie\n",
    "        categorie = CATEGORIES.index(category_widget.value)\n",
    "\n",
    "        # Prédiciton de la heatmap\n",
    "        heatmap = model(tf.expand_dims(image,0))\n",
    "        x,y = GetCoordFromHeatmap(heatmap)\n",
    "   \n",
    "        prediction = image.copy()\n",
    "        prediction = cv2.circle(prediction, (x, y), 8, (255, 0, 0), 3)\n",
    "        preview_widget.value = bgr8_to_jpeg(prediction)\n",
    "       \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        global execute_thread\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, base_model, camera))\n",
    "        execute_thread.start()\n",
    "    else:\n",
    "        execute_thread.join()\n",
    "       \n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget,preview_widget]),category_widget,state_widget])\n",
    "\n",
    "\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
