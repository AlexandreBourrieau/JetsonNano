{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en place de la caméra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de la caméra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw----+ 1 root video 81, 0 sept.  4 12:10 /dev/video0\r\n",
      "crw-rw----+ 1 root video 81, 4 sept.  4 12:10 /dev/video1\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la classe Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import threading\n",
    "import atexit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera(traitlets.HasTraits):\n",
    "    type_camera = traitlets.Unicode(\"CSI\")\n",
    "    capture_device = traitlets.Integer(default_value=0)\n",
    "    capture_width = traitlets.Integer(default_value=1280)\n",
    "    capture_height = traitlets.Integer(default_value=720)\n",
    "    display_width = traitlets.Integer(default_value=640)\n",
    "    display_height = traitlets.Integer(default_value=480)\n",
    "    fps = traitlets.Integer(default_value=30)\n",
    "    flip = traitlets.Integer(default_value=0)\n",
    "    image = traitlets.Any()\n",
    "    video_on = traitlets.Bool(default_value=False)\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "        self._running = False\n",
    "        self.image = np.empty((self.display_height, self.display_width, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "    \n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            image_resized = cv2.resize(image,(int(self.display_width),int(self.display_height)))\n",
    "        return image_resized\n",
    "    \n",
    "    # ON/OFF de la capture vidéo\n",
    "    def capture_video(self,run=False):\n",
    "        if run is True:\n",
    "            self.video_on = True\n",
    "        else:\n",
    "            self.video_on = False\n",
    "    \n",
    "    # Lecture d'un flux vidéo\n",
    "    def _capture_video(self):\n",
    "        while True:\n",
    "            if not self._running:\n",
    "                break\n",
    "            self.image = self.capture_image()\n",
    "\n",
    "            \n",
    "    # Détachement de la caméra\n",
    "    def release(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))\n",
    "    \n",
    "    # Surveillance de la variable \"video_on\"\n",
    "    @traitlets.observe('video_on')\n",
    "    def _on_running(self, change):\n",
    "        if change['new'] and not change['old']:\n",
    "            # not running -> running\n",
    "            self._running = True\n",
    "            self.thread = threading.Thread(target=self._capture_video)\n",
    "            self.thread.start()\n",
    "        elif change['old'] and not change['new']:\n",
    "            # running -> not running\n",
    "            self._running = False\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciation de la classe Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitCamera():\n",
    "    camera = Camera(type_camera=\"USB\",capture_device=1,\n",
    "                capture_width=640,capture_height=480,\n",
    "                display_width=320,display_height=200,\n",
    "                fps=30,flip=0)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des données d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par créer une interface à l'aide des widgets permettant de récupérer les données et de les sauvegarder dans un dictionnaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TACHE = # à compléter\n",
    "CATEGORIES = # à compléter\n",
    "datasets = {}\n",
    "for name in CATEGORIES:\n",
    "    datasets[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Initialise la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "camera = InitCamera()\n",
    "\n",
    "# Création du widget de la vidéo\n",
    "camera_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Création des widgets de l'interface\n",
    "category_widget = ipywidgets.Dropdown(options=CATEGORIES, description='Catégorie')\n",
    "count_widget = ipywidgets.IntText(description='Nombre')\n",
    "save_widget = ipywidgets.Button(description='Ajouter')\n",
    "\n",
    "# Mise à jour du nombre de données dans les catégories\n",
    "def update_counts(change):\n",
    "    count_widget.value = len(datasets[change['new']])\n",
    "count_widget.value = len(datasets[category_widget.value])\n",
    "category_widget.observe(update_counts, names='value')\n",
    "\n",
    "# Prise d'une image\n",
    "def save(c):\n",
    "    datasets[category_widget.value].append(camera.image)\n",
    "    count_widget.value = len(datasets[category_widget.value])\n",
    "save_widget.on_click(save)\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget]), category_widget, count_widget, save_widget])\n",
    "\n",
    "# Lancement de la vidéo\n",
    "camera.capture_video(run=True)\n",
    "camera_link = traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Affiche l'interface\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont sauvegardées en respectant la structure requise par la fonction tf.keras.preprocessing.image_dataset_from_directory : https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire_courant = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire_courant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des répertoires de sauvegarde\n",
    "try:\n",
    "    shutil.rmtree(repertoire_courant+\"/projet_classification/\"+TACHE)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "for i in range(len(CATEGORIES):\n",
    "    try:\n",
    "        shutil.rmtree(repertoire_courant+\"/projet_classification/\"+TACHE+\"/\"+CATEGORIES[i])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    os.makedirs(repertoire_courant+\"/projet_classification/\"+TACHE+\"/\"+CATEGORIES[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement des images\n",
    "for i in range (len(CATEGORIES)):\n",
    "    n = 0\n",
    "    for image in datasets[CATEGORIES[i]]:\n",
    "        n = n+1\n",
    "        cv2.imwrite(repertoire_courant+\"/projet_classification/\"+TACHE+\"/\"+CATEGORIES[i]+\"/\"+CATEGORIES[i]+\"_image_%d.jpg\" %n,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des images dans le dataset d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des images sauvegardées dans le répertoire de travail, on peut maintenant créer notre dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_entrainement = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    repertoire_courant+\"/projet_classification/\"+TACHE,\n",
    "    validation_split=0.0,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=5,\n",
    "    label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset_entrainement.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons le format du tenseur contenu dans le dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(2):\n",
    "    print(image.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons comment est codée une image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(1):\n",
    "    print(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons quelques labels codé de manière \"categorical\" et leur valeur équivalente \"binaire\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(3):\n",
    "    print(\"Label categorical : %s\" %label[0])\n",
    "    print(\"Label binaire correspondant : %s\" %np.argmax(label[0], axis=None, out=None))\n",
    "    print(\"Classe correspondante : %s\" %class_names[np.argmax(label[0], axis=None, out=None)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant quelques images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(dataset_entrainement)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    image, label = iterator.get_next()\n",
    "    plt.imshow(image[0].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[np.argmax(label[0], axis=None, out=None)])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique les transformations suivantes sur les images :\n",
    "    - Pour le Resnet18 : Il ne faut rien faire !\n",
    "    - Pour le Resnet50 : Il faut utiliser la méthode spécifique au Resnet50 de Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne convertit pas les valeurs !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la fonction https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_entrainement = dataset_entrainement.map(\n",
    "    lambda x,y: (tf.keras.applications.resnet50.preprocess_input(x),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons à quoi ressembles les images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(1):\n",
    "    print(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser le modèle ResNet50, on utilise les applications disponnibles dans Keras : https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet',\n",
    "                                                     include_top=False,\n",
    "                                                     input_shape=(224,224,3),\n",
    "                                                     pooling=False)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désactivation des couches poru l'entrainement\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de l'applatissement des sorties et de la couche dense avec 2 neurones\"\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(units=2, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=[base_model.input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des couches du modèle\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[165:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser le modèle RestNet18, nous allons utiliser le package Image-classifiers disponnible sur le github : https://github.com/AlexandreBourrieau/classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification_models\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle ResNEt18\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "\n",
    "# Instanciation du modèle pré-entrainé ResNet18\n",
    "base_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False,pooling=False)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désactivation des couches pour l'entrainement\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de l'applatissement des sorties et de la couche dense avec 2 neurones\"\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = # à compléter\n",
    "model = tf.keras.Model(inputs=[base_model.input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des couches du modèle\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[68:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de périodes d'entrainement\n",
    "periodes = 5\n",
    "\n",
    "# Entrainement du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(dataset_entrainement,verbose=1,epochs=periodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérimentations et évaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de pré-traitement de l'image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ci-dessous permet de traiter l'image avant de réaliser la prédiction avec le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_image(image):\n",
    "    image = tf.image.resize(image,[224,224])\n",
    "#    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'interface d'acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "camera = InitCamera()\n",
    "\n",
    "# Création du widget de la vidéo\n",
    "camera_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Lancement de la vidéo\n",
    "camera.capture_video(run=True)\n",
    "camera_link = traitlets.dlink((camera, 'image'), (camera_widget, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des widgets\n",
    "prediction_widget = ipywidgets.Text(description='prediction')\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "\n",
    "# Initialisation des scores dans le widgets Slider\n",
    "score_widgets = []\n",
    "for categorie in CATEGORIES:\n",
    "    score_widget = ipywidgets.FloatSlider(min=0.0, max=1.0, description=categorie, orientation='vertical')\n",
    "    score_widgets.append(score_widget)\n",
    "\n",
    "\n",
    "# Fonction de traitement des actions du widget \"state_widget\"\n",
    "def live(state_widget, model, camera, prediction_widget, score_widget):\n",
    "    global dataset\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.image\n",
    "        image = traitement_image(image)\n",
    "        output = model(tf.expand_dims(image,0))\n",
    "        score_widgets[1].value = # à coppléter\n",
    "        # à compléter\n",
    "        # ...\n",
    "       \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        global execute_thread\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, model, camera, prediction_widget, score_widget))\n",
    "        execute_thread.start()\n",
    "    else:\n",
    "        execute_thread.join()\n",
    "    \n",
    "       \n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox(score_widgets),\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "all_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget,live_execution_widget])])\n",
    "\n",
    "display(all_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fermeture de la caméra et du kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extinction de la caméra\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
