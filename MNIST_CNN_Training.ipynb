{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN77vsrTjM04"
   },
   "source": [
    "## Réseau neuronal convolutif\n",
    "\n",
    "Les [réseaux de neurones à convolution](https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_convolutif) (Convolutional Neural Networks - CNNs) ont de larges applications, en particulier dans la reconnaissance d'image et de vidéo. Leur structure est inspirée par celle du cortex visuel des animaux.\n",
    "\n",
    "Cet exemple nécessite Python 3, Tensorflow 2, matplotlib, et numpy. Entrainer un réseau de neurones à convolution demande davantage de temps de calcul qu'un réseau de base, entièrement connecté. C'est la raison pour laquelle l'entrainement par GPU est préféré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mHWfBk3sjM1m"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgM5FuvXjM15"
   },
   "source": [
    "Quelques configurations des paramètres et des hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L9Nu8uRSjM18"
   },
   "outputs": [],
   "source": [
    "# Dimensions des images d'entrée : 28x28\n",
    "dim_img_lignes, dim_img_colonnes = 28, 28\n",
    "\n",
    "# Nombre d'échantillons d'entrainement par lot. 128 est un nombre raisonable\n",
    "batch_size = 128\n",
    "\n",
    "# Les données contiennent 10 chiffres\n",
    "nbr_classes = 10\n",
    "\n",
    "# Nombre d'itérations à utiliser.\n",
    "iterations = 5\n",
    "\n",
    "# dropout est un hyperparamètre de régularisation. Il permet d'éviter la mémorisation pure et simple des entrées.\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB_ROKhkjM2H"
   },
   "source": [
    "### Chargement des données\n",
    "\n",
    "Keras possède des fonctions intégrées pour charger la base données MNIST, qui est par défaut structurée avec des données réservées pour l'entrainement et les tests.  \n",
    "* x_entrainement and x_test sont les variables utilisées pour sauvegarder les échantillons d'entrainement et de tests. Les images sont représentées dans une matrice de 28x28 pixels.  \n",
    "* y_entrainement et y_test sont les variables utilisées pour sauvegarder les valeurs attendues (les labels qui correspondent à chaque image manuscrite, c'est-à-dire le chiffre correspondant) d'entrainement et de tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xNZd9SiqlLPo"
   },
   "outputs": [],
   "source": [
    "(x_entrainement, y_entrainement), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Sauvegarde des échantillons des images de tests dans une variable intermédiaire \n",
    "# pour regarder un peu comment ces données sont structurées\n",
    "orig_test = x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGUVT3axlc23"
   },
   "source": [
    "La cellule suivante permet de visualiser des images réservées aux tests au hasard afin de se faire une idée de ce à quoi elles ressemblent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qEFrHyHVlXtF"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e3d0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randrange(1000)\n",
    "plt.imshow(orig_test[index], cmap='gray')\n",
    "plt.title('Label: %d' % y_test[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_entrainement.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOns6ruZlMrD"
   },
   "source": [
    "### Préparation des données\n",
    "\n",
    "Les données sont structurées afin d'être compatibles avec la forme d'entrée attendue par Keras :\n",
    "*  Soit du type : (RGB, X, Y)  \n",
    "*  Soit du type : (X, Y, RGB)  \n",
    "\n",
    "La valeur des pixels sont normalisées entre 0.0 et 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "AcbM1pEqjM2L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_entrainement = x_entrainement.reshape(x_entrainement.shape[0], 1, dim_img_lignes, dim_img_colonnes)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, dim_img_lignes, dim_img_colonnes)\n",
    "    input_shape = (1, dim_img_lignes, dim_img_colonnes)\n",
    "else:\n",
    "    x_entrainement = x_entrainement.reshape(x_entrainement.shape[0], dim_img_lignes, dim_img_colonnes, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], dim_img_lignes, dim_img_colonnes, 1)\n",
    "    input_shape = (dim_img_lignes, dim_img_colonnes, 1)\n",
    "    \n",
    "x_entrainement, x_test = x_entrainement / 255.0, x_test / 255.0\n",
    "\n",
    "print(x_entrainement.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "JCmaGB5o76tS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_entrainement.shape\n",
    "#x_entrainement[0,:,:,:]\n",
    "#x_entrainement\n",
    "#x_entrainement.reshape(x_entrainement.shape[0], 1, dim_img_lignes, dim_img_colonnes).shape\n",
    "#x_entrainement.reshape(x_entrainement.shape[0], dim_img_lignes, dim_img_colonnes,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWEsjkQ5jM2v"
   },
   "source": [
    "### Definition du modèle\n",
    "\n",
    "Des modèles avec plus de 100 réseaux de neurones à convolution, des couches de  pooling, padding, et autres couches ont permis d'être entrainés avec succès afin de reconnaitre des objets complexes ainsi que de multiples objets dans une image.\n",
    "\n",
    "La structure du modèle que nous allons utliser est la suivante :  \n",
    "* Deux [couches de convolution 2D](https://keras.io/api/layers/convolution_layers/convolution2d/) avec des fonctions d'activation de type redresseur (ReLU) ;  \n",
    "* Une [couche de pooling max](https://keras.io/api/layers/pooling_layers/max_pooling2d/) suivie d'une couche de régularisation de type [dropout](https://keras.io/api/layers/regularization_layers/dropout/) ;\n",
    "*  Une [couche d'aplatissement](https://keras.io/api/layers/reshaping_layers/flatten/) ;\n",
    "* Une [couche dense](https://keras.io/api/layers/core_layers/dense/) avec une fonction d'activation de type redresseur (ReLU) ;  \n",
    "* Une régularisation de type [dropout](https://keras.io/api/layers/regularization_layers/dropout/) ;\n",
    "* Une [couche dense](https://keras.io/api/layers/core_layers/dense/) avec une fonction d'activation de type Soft-Max. Cette dernière couche réalise la classification de type \"1 parmi n\" (One-hot encoded).  \n",
    "  \n",
    "Avec seulement des quelques couches, ce modèle permet d'attendre une précision de 99 %.  \n",
    "La structure de notre modèle peut être visualisée comme ci-dessous :  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/MNIST/Images/ReseauConvolutionKeras.jpg?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "mF5kDTK3jM2y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout/2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(nbr_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMHjxcZEjM26"
   },
   "source": [
    "### Entrainement du modèle\n",
    "\n",
    "Le code qui suit passe les données d'entrainement à Keras pour entrainer le modèle. La librairie Matplotlib est utilisée pour afficher la précision des entrainements et des tests, en fonction des itérations.\n",
    "\n",
    "Dans l'idéal, la précision obtenue avec les données de tests et d'entrainements devrait être la même.  \n",
    "* Une faible précision obtenue avec les données d'entrainements signifie que le modèle souffre d'un biais important. Cela peut être dû à un modèle qui n'est pas assez robuste, ou un manque de données d'entrainements, ou un trop petit nombre d'itérations.  \n",
    "* Une grande précision obtenue avec des données d'entrainements mais une faible précision obtenue avec les données de tests signifie que le modèle souffre d'une variance élevée. Le modèle est plus ou moins en train de mémoriser les données et non d'apprendre réellement. Ce problème peut être réglé à l'aide de régularisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Entraine le modèle sur un certain nombre d'itérations\n",
    "historique = model.fit(x_entrainement, y_entrainement, batch_size=batch_size, epochs=iterations, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evalue la précision du modèle avec les données de tests\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Pertes (Test) :', score[0])\n",
    "print('Précision (Test) :', score[1])\n",
    "\n",
    "# Affiche les informations\n",
    "plt.plot(historique.history['accuracy'])\n",
    "plt.plot(historique.history['val_accuracy'])\n",
    "plt.title('Précision du modèle')\n",
    "plt.ylabel('Précision')\n",
    "plt.xlabel('Itérations')\n",
    "plt.legend(['Entrainement', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmGm6OSVjM3G"
   },
   "source": [
    "### Prédictions\n",
    "\n",
    "Réalisons maintenant quelques prédictions en utilisant le modèle entrainé précédent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q42ckWf6jM3K"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "plus_probable = predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpQfEOHrfTC9"
   },
   "outputs": [],
   "source": [
    "plus_probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFh7qmw-jM3S"
   },
   "source": [
    "La cellule suivante choisit une image au hasard parmi les images de tests, affiche l'image ainsi que les valeurs prédites et attendues (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hmx7E54jjM3V"
   },
   "outputs": [],
   "source": [
    "index = random.randrange(10000)\n",
    "plt.title('Prédiction: %d, label: %d' % (plus_probable[index], y_test[index]))\n",
    "plt.imshow(orig_test[index], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9wOZZiXjM3b"
   },
   "source": [
    "### Analyse des erreurs\n",
    "\n",
    "Cette dernière cellule recherche les prédictions du modèle qui n'ont pas fonctionnées. Dans certains cas, même un humain ne pourrait trouver la bonne réponse !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoOvG05sjM3d"
   },
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    index = random.randrange(10000)\n",
    "    if plus_probable[index] != y_test[index]:\n",
    "        break\n",
    "\n",
    "plt.imshow(orig_test[index], cmap='gray')\n",
    "plt.title('Prédiction: %d, label: %d' % (plus_probable[index], y_test[index]))\n",
    "plt.show()\n",
    "\n",
    "plt.bar(range(10), predictions[index], tick_label=range(10))\n",
    "plt.title('Valeur prédite')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_CNN_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
